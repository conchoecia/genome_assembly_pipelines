"""
This snakefile sorts small scaffolds in a genome assembly based on their best
  possible location relative to the chromosome-scale scaffolds. This makes it
  easier later to curate the assembly.

The chromosomes must be specified in the config file like this:

chromosomes:
  - Scaffold1
  - Scaffold2
  - Scaffold3
  - Chr4
  - Chr_et_cetera

The output of this snakefile is a fasta file in which the chromosome-scale
  scaffolds are in the order specified in the config, and the small scaffolds
  are sorted.
"""

from Bio import SeqIO
import gzip
import os
import sys
minchromsize = 1000000
configfile: "config.yaml"
config["tool"]    = "GAP_sort_scaffolds_by_hic"
config["binsize"] = [50000]
qvals             = [0]

for x in config["assemblies"]:
    if "_" in x:
        raise IOError("You must not have any special characters in the assembly names: {}. Just use [A-Za-z0-9]+".format(x))

if "chromosomes" not in config:
    raise IOError("You must specify chromosomes in the config file.")

filepath = os.path.dirname( os.path.realpath(workflow.snakefile))
kmer_position_path=os.path.join(filepath, "../bin/kmer_positions.py")
picard_path=os.path.join(       filepath, "../bin/picard.jar")
chromappath = os.path.join(     filepath, "../bin/chromap/chromap")
bedsort_path=os.path.join(      filepath, "../bin/bedSort")
bed2bw_path=os.path.join(       filepath, "../bin/bedGraphToBigWig")

def rc(seq):
    """
    reverse complement the sequence
    """
    this_complement = {'A': 'T', 'C': 'G', 'G': 'C', 'T': 'A'}
    return "".join(this_complement.get(base, base) for base in reversed(seq))

def flatten(list_of_lists):
    if len(list_of_lists) == 0:
        return list_of_lists
    if isinstance(list_of_lists[0], list):
        return flatten(list_of_lists[0]) + flatten(list_of_lists[1:])
    return list_of_lists[:1] + flatten(list_of_lists[1:])

def nx(seq, n):
    """
    concats the sequence n times
    """
    return "".join([seq]*n)

if "minimap2arg" not in config:
    config["minimap2arg"] = "map-hifi"

###
###  KMER PARSING SECTION
###
# if kmers not specified in config, add
if "kmers" not in config:
    config["kmers"] = {}

# if telomere kmers not specified in the config file, use regular metazoan seq
if "telomere" not in config:
    config["telomere_seqs"] = ["TTAGGG"]
config["telomere_seqs"] = [x.upper() for x in config["telomere_seqs"]]

# make sure that there are no reverse complements in the telomere_seqs
#  we don't want this because we specifically define the revcomp in the
#  next step
for x in config["telomere_seqs"]:
    if rc(x) in config["telomere_seqs"]:
        raise IOError("Don't include the reverse reverse complement of the telomere sequences")
config["telomere_seqs"] = {"{}5x".format(key.upper()):
                           {"f":nx(key.upper(), 5),
                            "r":nx(rc(key.upper()), 5)}
                           for key in config["telomere_seqs"]}

print(config["telomere_seqs"])

# make sure all the kmers are uppercase and that the set is complete
for key in config["kmers"]:
    config["kmers"][key] = list(set([x.upper() for x in config["kmers"][key]] + \
                           [reverse_complement(x.upper()) for x in config["kmers"][key]]))
print(config["kmers"])

# make this dummy LR fastq file in case we don't actually want to map any reads
toolpath = os.path.join(os.getcwd(), config["tool"])
if not os.path.exists(toolpath):
    os.mkdir(toolpath)
if "LR" not in config:
    config["LR"] = [os.path.join(toolpath, "temp_dont_delete_me.fastq.gz")]
    if not os.path.exists(config["LR"][0]):
        content = b""
        f = gzip.open(config["LR"][0], 'wb')
        f.write(content)
        f.close()

# make this dummy transcript file in case we don't actually want to map any reads
toolpath = os.path.join(os.getcwd(), config["tool"])
if not os.path.exists(toolpath):
    os.mkdir(toolpath)
if "transcripts" not in config:
    config["transcripts"] = [os.path.join(toolpath, "temp_dont_delete_me.fastq.gz")]
    if not os.path.exists(config["transcripts"][0]):
        content = b""
        f = gzip.open(config["transcripts"][0], 'wb')
        f.write(content)
        f.close()

# now we check the LR and transcript files to make sure they are fasta or fastq
for thiskey in ["transcripts", "LR"]:
    for entry in config[thiskey]:
        good = False
        for ending in [".fa", ".fa.gz", ".fasta",
                       ".fasta.gz", ".fastq",
                       ".fastq.gz", ".fq", ".fq.gz"]:
            if entry.endswith(ending):
                good = True
        if not good:
            raise IOError ("The LR or transcripts file {} must end with .fa, .fa.gz, .fasta, .fasta.gz, .fastq, or .fastq.gz.".format(entry))

def get_chromosome_sizes(assembly_file, minsize):
    """
    returns a set of chromosomes to keep
    """
    chroms = []
    with open(assembly_file) as handle:
        for record in SeqIO.parse(handle, "fasta"):
            if len(record.seq) >= minsize:
                chroms.append(record.id)
    return chroms

wildcard_constraints:
    datatype="[A-Za-z0-9]+",
    kmer="[A-Za-z0-9]+",
    nom="[A-Za-z0-9.]+",
    telo="[A-Za-z0-9]+",
    binsize="[0-9]+",
    qval="[0-9]+",
    telodir="[fr]"

rule all:
    input:
        # chromsize
        expand(config["tool"] + "/output/{nom}/{nom}_chromsize.txt",
               nom = config["assemblies"]),
        expand(config["tool"] + "/output/{nom}/text_hic_map/{nom}.q_{qval}.{binsize}.gi.tsv",
               nom = config["assemblies"], qval = qvals, binsize=config["binsize"]),
        expand(config["tool"] + "/output/{nom}/text_hic_map/{nom}.q_{qval}.{binsize}.gi.nonchroms.best.tsv",
               nom = config["assemblies"], qval = qvals, binsize=config["binsize"]),
        expand(config["tool"] + "/output/assembly/{nom}_q_{qval}_{binsize}_output.fasta",
               nom = config["assemblies"], qval = qvals, binsize=config["binsize"]),

# make softlinks of the input files
# files end up here:
#   assem = config["tool"] + "/input/assembly/{nom}_input.fasta",
filepath = os.path.dirname(os.path.realpath(workflow.snakefile))
softlinks_rule_path=os.path.join(filepath, "snakemake_includes/assembly_softlinks")
include: softlinks_rule_path

rule chrom_size:
    """
    make a file with the chromosome sizes
    """
    input:
        assem = config["tool"] + "/input/assembly/{nom}_input.fasta"
    output:
        cs = config["tool"] + "/output/{nom}/{nom}_chromsize.txt"
    threads: 1
    shell:
        """
        bioawk -cfastx '{{printf("%s\\t%d\\n", $name, length($seq))}}' {input.assem} > {output.cs}
        """

#      _ ___   _ _____     _    _       __ _ _
#   _ | | _ ) /_\_   _|   | |_ (_)__   / _(_) |___ ___
#  | || | _ \/ _ \| |    _| ' \| / _| |  _| | / -_|_-<
#   \__/|___/_/ \_\_|   (_)_||_|_\__| |_| |_|_\___/__/
#
rule compile_chromap:
    """
    compile chromap if it does not yet exist
    """
    output:
        chromap = os.path.join(filepath, "../bin/chromap/chromap")
    params:
        mvdir = os.path.join(filepath, "../bin/")
    threads: 1
    shell:
        """
        git clone https://github.com/haowenz/chromap.git
        cd chromap
        make
        cd ..
        mv chromap/ {params.mvdir}
        """

rule index_ref:
    input:
        assem = config["tool"] + "/input/assembly/{nom}_input.fasta",
        chromap = os.path.join(filepath, "../bin/chromap/chromap")
    output:
        index = temp(config["tool"] + "/input/assembly/{nom}_input.fasta.index")
    shell:
        """
        {input.chromap} -i -r {input.assem} -o {output.index}
        """

rule hic_to_pairs:
    input:
        assem   = config["tool"] + "/input/assembly/{nom}_input.fasta",
        index   = config["tool"] + "/input/assembly/{nom}_input.fasta.index",
        chromap = chromappath,
        left  = flatten([config["libs"][x]["read1"] for x in config["libs"]]),
        right = flatten([config["libs"][x]["read2"] for x in config["libs"]])
    output:
        pairs = config["tool"] + "/output/pairs/{nom}/{nom}_q_{qval}.pairs"
    params:
        left  = " -1 ".join(flatten([config["libs"][x]["read1"] for x in config["libs"]])),
        right = " -2 ".join(flatten([config["libs"][x]["read2"] for x in config["libs"]])),
        qval  = lambda wildcards: wildcards.qval
    threads: workflow.cores - 2
    shell:
        """
        {input.chromap} --preset hic -x {input.index} \
            -r {input.assem} \
            -1 {params.left}  \
            -2 {params.right} \
            -t {threads} \
            -q {params.qval} \
            -o {output.pairs}
        """

def pairs_to_counts(pairs_file, binsize, output_file):
    """
    reads in a pairs file and saves a counts file

    input looks like this:
    ## pairs format v1.0.0
    #shape: upper triangle
    #chromsize: c1 26206493
    #chromsize: c2 23028209
    #chromsize: c3 21284423
    #chromsize: c4 16326010
    #chromsize: c5 23637599
    #chromsize: sca332 2526
    #chromsize: sca333 1772
    #chromsize: Binf1_mitogenome 10476
    #columns: readID chrom1 pos1 chrom2 pos2 strand1 strand2 pair_type
    E00521:324:HC73WCCX2:4:2103:31487:71506 c1      24      c1      167     +       -       UU
    E00521:324:HC73WCCX2:4:2213:14336:42323 c1      25      c1      181     +       -       UU
    E00521:324:HC73WCCX2:4:1206:18964:4983  c1      25      c1      457     +       -       UU
    E00521:324:HC73WCCX2:5:2201:18406:8904  c1      41      c1      190     +       -       UU
    E00521:324:HC73WCCX2:4:1215:9638:9326   c1      41      c1      938243  +       +       UU

    output looks like this:
    c1      0       50000   c1      0       50000   31880
    c1      0       50000   c1      50000   100000  526
    c1      0       50000   c1      100000  150000  26
    c1      0       50000   c1      150000  200000  22
    c1      0       50000   c1      200000  250000  36
    c1      0       50000   c1      250000  300000  52
    c1      0       50000   c1      300000  350000  39
    c1      0       50000   c1      350000  400000  78
    c1      0       50000   c1      400000  450000  57
    c1      0       50000   c1      450000  500000  44
    c1      0       50000   c1      500000  550000  73
    """
    chrom_to_size = {}
    chrom_order = []
    counts = {}
    counter = 0
    with open(pairs_file, "r") as f:
        for line in f:
            line = line.strip()
            if line:
                if line.startswith("#"):
                    if line.startswith("#chromsize: "):
                        fields = line.split()
                        chrom = fields[1]
                        size = int(fields[2])
                        chrom_to_size[chrom] = size
                        chrom_order.append(chrom)
                else:
                    # E00521:324:HC73WCCX2:4:2213:14336:42323 c1      25      c1      181     +       -       UU
                    # fields1 is chrom1
                    # fields2 is chrom1 pos
                    # fields3 is chrom2
                    # fields4 is chrom2 pos
                    fields = line.split("\t")
                    c1    = fields[1]
                    c1pos = int(int(fields[2])/binsize)
                    c2    = fields[3]
                    c2pos = int(int(fields[4])/binsize)

                    if c1 not in counts:
                        counts[c1] = {}
                    if c1pos not in counts[c1]:
                        counts[c1][c1pos] = {}
                    if c2 not in counts[c1][c1pos]:
                        counts[c1][c1pos][c2] = {}
                    if c2pos not in counts[c1][c1pos][c2]:
                        counts[c1][c1pos][c2][c2pos] = 0
                    counts[c1][c1pos][c2][c2pos] += 1

                    if counter % 1000 == 0:
                        print("  processed {} lines    ".format(counter), end = "\r")
                    counter += 1

    outhandle = open(output_file, "w")
    for c1 in [x for x in chrom_order if x in counts]:
        for c1pos in sorted(counts[c1]):
            for c2 in [x for x in chrom_order if x in counts[c1][c1pos]]:
                for c2pos in sorted(counts[c1][c1pos][c2]):
                    c1start = c1pos * binsize
                    c2start = c2pos * binsize
                    c1end = c1pos * binsize
                    c2end = c2pos * binsize
                    if chrom_to_size[c1] < c1end:
                        c1end = chrom_to_size[c1]
                    if chrom_to_size[c2] < c2end:
                        c2end = chrom_to_size[c2]
                    print("{}\t{}\t{}\t{}\t{}\t{}\t{}".format(
                        c1, c1start, c1end,
                        c2, c2start, c2end,
                        counts[c1][c1pos][c2][c2pos]),
                          file = outhandle)
    outhandle.close()

rule python_pairs_to_map:
    input:
        pairs = config["tool"] + "/output/pairs/{nom}/{nom}_q_{qval}.pairs"
    output:
        hicm = config["tool"] + "/output/{nom}/text_hic_map/{nom}.q_{qval}.{binsize}.gi.tsv"
    params:
        binsize = lambda wildcards: int(wildcards.binsize)
    run:
        pairs_to_counts(input.pairs, params.binsize, output.hicm)

rule hicmatrix_nonchroms:
    """
    Gets rid of the rows in the matrix that are chrom-chrom interactions or
      scaf-scaf interactions. These aren't useful for sorting.
    """
    input:
        hicm = config["tool"] + "/output/{nom}/text_hic_map/{nom}.q_{qval}.{binsize}.gi.tsv"
    output:
        hicm = config["tool"] + "/output/{nom}/text_hic_map/{nom}.q_{qval}.{binsize}.gi.nonchroms.tsv"
    threads: 1
    run:
        outhandle = open(output.hicm, "w")
        with open(input.hicm, "r") as f:
            for line in f:
                line = line.strip()
                if line:
                    fields = line.split()
                    s1 = True if fields[0] in config["chromosomes"] else False
                    s2 = True if fields[3] in config["chromosomes"] else False
                    printme = True
                    if s1 and s2:
                        printme = False
                    elif not s1 and not s2:
                        printme = False
                    if printme:
                        # this always prints the chromosome in the second column
                        if s1:
                            linemod = "\t".join([str(x) for x in [
                                 fields[3], fields[4], fields[5],
                                 fields[0], fields[1], fields[2], fields[6]
                                                                 ]])
                            print(linemod, file = outhandle)
                        elif s2:
                            print(line, file = outhandle)
                        else:
                            raise IOError("Shouldn't be here")

rule summarize_matrix_by_chromosome_coordinate:
    """
    Each scaffold must now be represented by a single value along the axis of
      chromosome coordinates.
    """
    input:
        hicm = config["tool"] + "/output/{nom}/text_hic_map/{nom}.q_{qval}.{binsize}.gi.nonchroms.tsv"
    output:
        hicm = config["tool"] + "/output/{nom}/text_hic_map/{nom}.q_{qval}.{binsize}.gi.nonchroms.best.tsv"
    threads: 1
    run:
        import pandas as pd
        df = pd.read_csv(input.hicm, sep = "\t", header = None)
        df.columns = ["scaf", "start", "stop", "chrom", "cstart", "cstop", "count"]
        grouped_df = df.groupby(["scaf", "chrom", "cstart", "cstop"], as_index = False)["count"].sum()

        gb = grouped_df.groupby(["scaf", "chrom"], as_index = False)

        keeps = []
        for name, group in gb:
            # This makes a rolling window sum of the counts to get a more accurate
            #  estimate of the best position. It centers the value and sums up
            # 10 windows around it.
            pd.set_option('display.max_rows', 5000)
            group["window"] = group["count"].shift(-4).rolling(7).sum().fillna(0)
            temp = group.sort_values(["window", "count"], ascending = [False, False])
            keeps.append(temp.iloc[0])

        newdf = pd.DataFrame(keeps, columns=["scaf", "chrom", "cstart", "cstop", "count", "window"])
        newdf = newdf.reset_index(drop = True)

        # get the best chrom for each scaffold
        gb = newdf.groupby(["scaf"], as_index = False)
        keeps = []
        for name, group in gb:
            temp = group.sort_values(["window", "count"], ascending = [False, False])
            keeps.append(temp.iloc[0])

        newdf = pd.DataFrame(keeps, columns=["scaf", "chrom", "cstart", "cstop", "count", "window"])
        newdf = newdf.sort_values(["chrom", "cstart", "cstop"], ascending = [True, True, True])
        newdf = newdf.reset_index(drop = True)

        newdf.to_csv(output.hicm, sep = "\t", header = None, index = None)

rule output_sorted_fasta:
    """
    Outputs a new fasta file with the scaffolds sorted by best
     chromosome position
    """
    input:
        hicm  = config["tool"] + "/output/{nom}/text_hic_map/{nom}.q_{qval}.{binsize}.gi.nonchroms.best.tsv",
        assem = config["tool"] + "/input/assembly/{nom}_input.fasta"
    output:
        assem = config["tool"] + "/output/assembly/{nom}_q_{qval}_{binsize}_output.fasta"
    threads: 1
    run:
        chrom_to_scaf_order = {}
        # get the order of chromosomes as they occur in the config
        with open(input.hicm, "r") as f:
            for line in f:
                line = line.strip()
                if line:
                    fields = line.split("\t")
                    chrom  = fields[1]
                    scaf   = fields[0]
                    if chrom not in chrom_to_scaf_order:
                        chrom_to_scaf_order[chrom] = []
                    chrom_to_scaf_order[chrom].append(scaf)
        #now read in the genome
        chrom_order = [x for x in config["chromosomes"]]
        unseen_chromosomes = [x for x in config["chromosomes"]]
        unprinted  = []
        scaf_dict = {}
        # this syntax is safe for newer versions of python, don't use "rU" anymore
        with open(input.assem, newline = "") as handle:
            for record in SeqIO.parse(handle, "fasta"):
                scaf_dict[record.id] = record
                if record.id in config["chromosomes"]:
                    unseen_chromosomes.remove(record.id)
                else:
                    unprinted.append(record.id)
        # potentially an error here. Read this message
        if len(unseen_chromosomes) > 0:
            raise IOError("You specified these chromosomes but they were not in the fasta file: {}".format(unseen_chromosomes))

        print(chrom_order)
        # Should be safe to move forward now
        outhandle = open(output.assem, "w")
        # now print out everything
        for thischrom in chrom_order:
            print("printing ", thischrom)
            SeqIO.write(scaf_dict[thischrom], outhandle, "fasta")
            # this is redundant but just run it anyway. None of these should
            # be in the list
            if thischrom in unprinted:
                unprinted.remove(thischrom)
        # now write the other scaffolds
        for thischrom in chrom_order:
            if thischrom in chrom_to_scaf_order:
                for thisscaf in chrom_to_scaf_order[thischrom]:
                    SeqIO.write(scaf_dict[thisscaf], outhandle, "fasta")
                    if thisscaf in unprinted:
                        unprinted.remove(thisscaf)
        # now write the scaffolds that didn't have any Hi-C connections to anything
        for thisscaf in unprinted:
            SeqIO.write(scaf_dict[thisscaf], outhandle, "fasta")
        outhandle.close()
