"""
This snakefile runs blobtools on the assembly.
"""
configfile: "config.yaml"
config["tool"] = "GAP_blobtools_LR"

if "LR" not in config:
    raise IOError("You must specify the long reads in a yaml list in the config file. The reads must be in fastq.gz format")

if "minimap2arg" not in config:
    raise IOError("you must specify minimap2arg in the config to tell minimap2 what type of reads you're using.")

if config["minimap2arg"] not in ["map-pb", "map-ont", "map-hifi"]:
    raise IOError("You chose a read type for minimap2arg that will not work here. Choose map-pb, map-ont, or map-hifi")

rule all:
    input:
        #expand(config["tool"] + "/output/bams_LR/LR_all_to_{nom}.bam",
        #       nom = config["assemblies"])
        expand(config["tool"] + "/output/blobtools_{nom}/{nom}_blobtools.blobDB.json.bestsum.phylum.p7.span.100.blobplot.bam0.png",
               nom = config["assemblies"])

# this bit makes softlinks of the assemblies and maps the short reads
filepath = os.path.dirname(os.path.realpath(workflow.snakefile))
softlinks_rule_path=os.path.join(filepath, "snakemake_includes/assembly_softlinks")
include: softlinks_rule_path

rule symlink_the_LRs:
    """
    Symlinks the long reads so they are easier to work with in the rest of the
      pipeline
    """
    input:
        LR = config["LR"]
    output:
        assem = expand(config["tool"] + "/input/longreads/LR_{LRnum}.fastq.gz",
                       LRnum = list(range(0, len(config["LR"]))))
    params:
        fileprefix = config["tool"] + "/input/longreads/LR_",
        filesuffix = ".fastq.gz"
    run:
        for i in range(0, len(config["LR"])):
            thisLR = config["LR"][i]
            dest = "{}{}{}".format(params.fileprefix, i, params.filesuffix)
            os.symlink(thisLR, dest)

rule map_LR_to_genome:
    """
    maps the reads to the assembly
    """
    input:
        assem = config["tool"] + "/input/assembly/{nom}_input.fasta",
        long_reads = config["tool"] + "/input/longreads/LR_{LRnum}.fastq.gz"
    output:
        bam = config["tool"] + "/output/bams/LR_{LRnum}_to_{nom}.bam"
    params:
        minimaparg = config["minimap2arg"]
    threads: workflow.cores - 1
    shell:
        """
        minimap2 -t {threads} -ax {params.minimaparg} {input.assem} {input.long_reads} | \
          samtools view -hb - | \
          samtools sort - > {output.bam}
        """

rule index_bams:
    input:
        bam = config["tool"] + "/output/bams/LR_{LRnum}_to_{nom}.bam"
    output:
        bai = config["tool"] + "/output/bams/LR_{LRnum}_to_{nom}.bam.bai"
    threads: 1
    shell:
        """
        samtools index {input.bam}
        """

rule download_taxid:
    output:
        taxid_file = filepath + "/../db/nr_accesion_to_taxids.txt"
    threads: 1
    params:
        db = config["nr_db"]
    shell:
        """
        blastdbcmd -db {params.db} -entry all \
           -outfmt "%a %T" | \
           awk '{{print($1, "NCBI_TaxID", $2)}}' > {output.taxid_file}
        """

rule get_diamond_nr_hits:
    input:
        db = config["diamond_nr_db"],
        assembly = config["tool"] + "/input/assembly/{nom}_input.fasta",
        taxid_file = filepath + "/../db/nr_accesion_to_taxids.txt"
    output:
        dmnd_out = config["tool"] + "/input/dmnd/{nom}_dmnd.blastx"
    threads:
        workflow.cores - 1
    shell:
        """
        diamond blastx \
          --query {input.assembly} \
          --db {input.db} \
          --outfmt 6 \
          --sensitive \
          --evalue 0.001 \
          --threads {threads} \
          --out {output.dmnd_out}
        """

rule blobtools_taxonify:
    input:
        dmnd_out = config["tool"] + "/input/dmnd/{nom}_dmnd.blastx",
        taxid_file = filepath + "/../db/nr_accesion_to_taxids.txt"
    output:
        taxonify_out = config["tool"] + "/input/dmnd/{nom}_dmnd.blastx.taxified.out",
    params:
        outprefix = lambda wildcards: config["tool"] + "/input/dmnd/"
    shell:
        """
        blobtools taxify -f {input.dmnd_out} -m {input.taxid_file} -s 0 -t 2 -o {params.outprefix}
        """

rule blobtools_create:
    input:
        assembly = config["tool"] + "/input/assembly/{nom}_input.fasta",
        bams = expand(config["tool"] + "/output/bams/LR_{LRnum}_to_{{nom}}.bam",
                      LRnum = list(range(len(config["LR"]))) ),
        bais = expand(config["tool"] + "/output/bams/LR_{LRnum}_to_{{nom}}.bam.bai",
                      LRnum = list(range(len(config["LR"]))) ),
        taxonify_out = config["tool"] + "/input/dmnd/{nom}_dmnd.blastx.taxified.out",
    output:
        blob_results = config["tool"] + "/output/blobtools_{nom}/{nom}_blobtools.blobDB.json"
    params:
        blob_prefix  = config["tool"] + "/output/blobtools_{nom}/{nom}_blobtools",
        bam_string   = "-b ".join([config["tool"] + "/output/bams/LR_" + str(x) + "_to_{nom}.bam"
                                   for x in range(len(config["LR"]))])
    shell:
        """
        blobtools create \
           -i {input.assembly} \
           {params.bam_string} \
           -t {input.taxonify_out} \
           -o {params.blob_prefix}
        """

rule blobtools_view_and_plot:
    input:
        blob_results = config["tool"] + "/output/blobtools_{nom}/{nom}_blobtools.blobDB.json"
    output:
        blob_results = config["tool"] + "/output/blobtools_{nom}/{nom}_blobtools.blobDB.json.bestsum.phylum.p7.span.100.blobplot.bam0.png"
    params:
        mv_prefix = lambda wildcards: "{}_blobtools.blobDB.".format(wildcards.nom),
        mv_folder = lambda wildcards: config["tool"] + "/output/blobtools_{}/".format(wildcards.nom)
    threads: 1
    shell:
        """
        blobtools view -i {input.blob_results}
        blobtools plot -i {input.blob_results}
        mv {params.mv_prefix}* {params.mv_folder}
        """
