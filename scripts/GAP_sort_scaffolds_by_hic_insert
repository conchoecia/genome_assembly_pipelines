"""
This snakefile sorts small scaffolds in a genome assembly based on their best
  possible location relative to the chromosome-scale scaffolds. This makes it
  easier later to curate the assembly.

The chromosomes must be specified in the config file like this:

chromosomes:
  - Scaffold1
  - Scaffold2
  - Scaffold3
  - Chr4
  - Chr_et_cetera

The output of this snakefile is a fasta file in which the chromosome-scale
  scaffolds are in the order specified in the config, and the small scaffolds
  are sorted.
"""

from Bio import SeqIO
from Bio.Seq import Seq
from Bio.SeqRecord import SeqRecord

import gzip
import os
import pandas as pd
import sys
minchromsize = 1000000
configfile: "config.yaml"
config["tool"] = "GAP_sort_scaffolds_by_hic"
config["binsize"] = [50000]
qvals = [0]


for x in config["assemblies"]:
    if "_" in x:
        raise IOError("You must not have any special characters in the assembly names: {}. Just use [A-Za-z0-9]+".format(x))

if "chromosomes" not in config:
    raise IOError("You must specify chromosomes in the config file.")
if "min_insert_size" not in config:
    raise IOError("You must specify the min_insert_size in the config. The min size of the scaffold to insert.")
if "strength_fraction" not in config:
    raise IOError("You must specify the strength fraction. The fraction of the scaffolds based on Hi-C strength that you want to insert.")

filepath = os.path.dirname(os.path.realpath(workflow.snakefile))
kmer_position_path=os.path.join(filepath, "../bin/kmer_positions.py")
picard_path=os.path.join(filepath, "../bin/picard.jar")
chromappath = os.path.join(filepath, "../bin/chromap/chromap")
bedsort_path=os.path.join(filepath, "../bin/bedSort")
bed2bw_path=os.path.join(filepath,  "../bin/bedGraphToBigWig")

def rc(seq):
    """
    reverse complement the sequence
    """
    this_complement = {'A': 'T', 'C': 'G', 'G': 'C', 'T': 'A'}
    return "".join(this_complement.get(base, base) for base in reversed(seq))

def flatten(list_of_lists):
    if len(list_of_lists) == 0:
        return list_of_lists
    if isinstance(list_of_lists[0], list):
        return flatten(list_of_lists[0]) + flatten(list_of_lists[1:])
    return list_of_lists[:1] + flatten(list_of_lists[1:])

def nx(seq, n):
    """
    concats the sequence n times
    """
    return "".join([seq]*n)

if "minimap2arg" not in config:
    config["minimap2arg"] = "map-hifi"

###
###  KMER PARSING SECTION
###
# if kmers not specified in config, add
if "kmers" not in config:
    config["kmers"] = {}

# if telomere kmers not specified in the config file, use regular metazoan seq
if "telomere" not in config:
    config["telomere_seqs"] = ["TTAGGG"]
config["telomere_seqs"] = [x.upper() for x in config["telomere_seqs"]]

# make sure that there are no reverse complements in the telomere_seqs
#  we don't want this because we specifically define the revcomp in the
#  next step
for x in config["telomere_seqs"]:
    if rc(x) in config["telomere_seqs"]:
        raise IOError("Don't include the reverse reverse complement of the telomere sequences")
config["telomere_seqs"] = {"{}5x".format(key.upper()):
                           {"f":nx(key.upper(), 5),
                            "r":nx(rc(key.upper()), 5)}
                           for key in config["telomere_seqs"]}

print(config["telomere_seqs"])

# make sure all the kmers are uppercase and that the set is complete
for key in config["kmers"]:
    config["kmers"][key] = list(set([x.upper() for x in config["kmers"][key]] + \
                           [reverse_complement(x.upper()) for x in config["kmers"][key]]))
print(config["kmers"])

# make this dummy LR fastq file in case we don't actually want to map any reads
toolpath = os.path.join(os.getcwd(), config["tool"])
if not os.path.exists(toolpath):
    os.mkdir(toolpath)
if "LR" not in config:
    config["LR"] = [os.path.join(toolpath, "temp_dont_delete_me.fastq.gz")]
    if not os.path.exists(config["LR"][0]):
        content = b""
        f = gzip.open(config["LR"][0], 'wb')
        f.write(content)
        f.close()

# make this dummy transcript file in case we don't actually want to map any reads
toolpath = os.path.join(os.getcwd(), config["tool"])
if not os.path.exists(toolpath):
    os.mkdir(toolpath)
if "transcripts" not in config:
    config["transcripts"] = [os.path.join(toolpath, "temp_dont_delete_me.fastq.gz")]
    if not os.path.exists(config["transcripts"][0]):
        content = b""
        f = gzip.open(config["transcripts"][0], 'wb')
        f.write(content)
        f.close()

# now we check the LR and transcript files to make sure they are fasta or fastq
for thiskey in ["transcripts", "LR"]:
    for entry in config[thiskey]:
        good = False
        for ending in [".fa", ".fa.gz", ".fasta",
                       ".fasta.gz", ".fastq",
                       ".fastq.gz", ".fq", ".fq.gz"]:
            if entry.endswith(ending):
                good = True
        if not good:
            raise IOError ("The LR or transcripts file {} must end with .fa, .fa.gz, .fasta, .fasta.gz, .fastq, or .fastq.gz.".format(entry))

def get_chromosome_sizes(assembly_file, minsize):
    """
    returns a set of chromosomes to keep
    """
    chroms = []
    with open(assembly_file) as handle:
        for record in SeqIO.parse(handle, "fasta"):
            if len(record.seq) >= minsize:
                chroms.append(record.id)
    return chroms

wildcard_constraints:
    datatype="[A-Za-z0-9]+",
    kmer="[A-Za-z0-9]+",
    nom="[A-Za-z0-9.]+",
    telo="[A-Za-z0-9]+",
    binsize="[0-9]+",
    qval="[0-9]+",
    telodir="[fr]"

rule all:
    input:
        # chromsize
        expand(config["tool"] + "/output/{nom}/{nom}_chromsize.txt",
               nom = config["assemblies"]),
        expand(config["tool"] + "/output/{nom}/text_hic_map/{nom}.q_{qval}.{binsize}.gi.tsv",
               nom = config["assemblies"], qval = qvals, binsize=config["binsize"]),
        expand(config["tool"] + "/output/{nom}/text_hic_map/{nom}.q_{qval}.{binsize}.gi.nonchroms.best.tsv",
               nom = config["assemblies"], qval = qvals, binsize=config["binsize"]),
        expand(config["tool"] + "/output/assembly/{nom}_q_{qval}_{binsize}_output.fasta",
               nom = config["assemblies"], qval = qvals, binsize=config["binsize"]),

# make softlinks of the input files
# files end up here:
#   assem = config["tool"] + "/input/assembly/{nom}_input.fasta",
filepath = os.path.dirname(os.path.realpath(workflow.snakefile))
softlinks_rule_path=os.path.join(filepath, "snakemake_includes/assembly_softlinks")
include: softlinks_rule_path

rule chrom_size:
    """
    make a file with the chromosome sizes
    """
    input:
        assem = config["tool"] + "/input/assembly/{nom}_input.fasta"
    output:
        cs = config["tool"] + "/output/{nom}/{nom}_chromsize.txt"
    threads: 1
    shell:
        """
        bioawk -cfastx '{{printf("%s\\t%d\\n", $name, length($seq))}}' {input.assem} > {output.cs}
        """

#      _ ___   _ _____     _    _       __ _ _
#   _ | | _ ) /_\_   _|   | |_ (_)__   / _(_) |___ ___
#  | || | _ \/ _ \| |    _| ' \| / _| |  _| | / -_|_-<
#   \__/|___/_/ \_\_|   (_)_||_|_\__| |_| |_|_\___/__/
#
rule compile_chromap:
    """
    compile chromap if it does not yet exist
    """
    output:
        chromap = os.path.join(filepath, "../bin/chromap/chromap")
    params:
        mvdir = os.path.join(filepath, "../bin/")
    threads: 1
    shell:
        """
        git clone https://github.com/haowenz/chromap.git
        cd chromap
        make
        cd ..
        mv chromap/ {params.mvdir}
        """

rule index_ref:
    input:
        assem = config["tool"] + "/input/assembly/{nom}_input.fasta",
        chromap = os.path.join(filepath, "../bin/chromap/chromap")
    output:
        index = temp(config["tool"] + "/input/assembly/{nom}_input.fasta.index")
    shell:
        """
        {input.chromap} -i -r {input.assem} -o {output.index}
        """

rule hic_to_pairs:
    input:
        assem = config["tool"] + "/input/assembly/{nom}_input.fasta",
        index   = config["tool"] + "/input/assembly/{nom}_input.fasta.index",
        chromap = chromappath,
        left  = flatten([config["libs"][x]["read1"] for x in config["libs"]]),
        right = flatten([config["libs"][x]["read2"] for x in config["libs"]])
    output:
        pairs = config["tool"] + "/output/pairs/{nom}/{nom}_q_{qval}.pairs"
    params:
        left  = " -1 ".join(flatten([config["libs"][x]["read1"] for x in config["libs"]])),
        right = " -2 ".join(flatten([config["libs"][x]["read2"] for x in config["libs"]])),
        qval  = lambda wildcards: wildcards.qval
    threads: workflow.cores - 2
    shell:
        """
        {input.chromap} --preset hic -x {input.index} \
            -r {input.assem} \
            -1 {params.left}  \
            -2 {params.right} \
            -t {threads} \
            -q {params.qval} \
            -o {output.pairs}
        """

rule gzip_pairs:
    input:
        pairs = config["tool"] + "/output/pairs/{nom}/{nom}_q_{qval}.pairs"
    output:
        pairs = config["tool"] + "/output/pairs/{nom}/{nom}_q_{qval}.pairs.gz"
    threads: 1
    shell:
        """
        bgzip -c {input.pairs} > {output.pairs}
        """

rule index_pairs:
    """
    indexing output. the *.pairs.gz suffix is important to parse the file correctly!
    """
    input:
        pairs = config["tool"] + "/output/pairs/{nom}/{nom}_q_{qval}.pairs.gz",
    output:
        index = config["tool"] + "/output/pairs/{nom}/{nom}_q_{qval}.pairs.gz.px2"
    threads: 1
    shell:
        """
        pairix -f {input.pairs}
        """

rule make_bins_individual:
    """
    This makes the matrix and bins everything
    i.e. binsize: 5000 (high resolution), 500000 (lower resolution)
    """
    input:
        final = config["tool"] + "/output/pairs/{nom}/{nom}_q_{qval}.pairs.gz",
        index = config["tool"] + "/output/pairs/{nom}/{nom}_q_{qval}.pairs.gz.px2",
        cs = config["tool"] + "/output/{nom}/{nom}_chromsize.txt"
    output:
        cool = config["tool"] + "/output/{nom}/{nom}.q_{qval}.{binsize}.cool"
    threads: 1
    params:
        bs = lambda wildcards: wildcards.binsize,
        nom = lambda wildcards: wildcards.nom,
        outname = lambda wildcards: "{tool}/output/{nom}/{nom}.q_{qval}.{binsize}.cool".format(
            tool=config["tool"], nom = wildcards.nom,
            binsize = wildcards.binsize,
            qval = wildcards.qval)
    threads: max(8, int((workflow.cores -1)/4))
    shell:
        """
        cooler cload pairix --nproc {threads} {input.cs}:{params.bs} {input.final} {params.outname}
        """

# random stuff
#  ___              _                _         __  __
# | _ \__ _ _ _  __| |___ _ __    __| |_ _  _ / _|/ _|
# |   / _` | ' \/ _` / _ \ '  \  (_-<  _| || |  _|  _|
# |_|_\__,_|_||_\__,_\___/_|_|_| /__/\__|\_,_|_| |_|
#

# Now we get the Hi-C interaction matrix
rule make_hic_matrix_simple:
    input:
        cool = config["tool"] + "/output/{nom}/{nom}.q_{qval}.{binsize}.cool"
    output:
        hicm = config["tool"] + "/output/{nom}/text_hic_map/{nom}.q_{qval}.{binsize}.gi.tsv"
    params:
        gi = config["tool"] + "/output/{nom}/text_hic_map/{nom}.q_{qval}.{binsize}.gi"
    threads: 1
    shell:
        """
        hicConvertFormat -m {input.cool} \
           --outFileName {params.gi} \
           --inputFormat cool \
           --outputFormat ginteractions
        """

rule hicmatrix_nonchroms:
    """
    Gets rid of the rows in the matrix that are chrom-chrom interactions or
      scaf-scaf interactions. These aren't useful for sorting.
    """
    input:
        hicm = config["tool"] + "/output/{nom}/text_hic_map/{nom}.q_{qval}.{binsize}.gi.tsv"
    output:
        hicm = config["tool"] + "/output/{nom}/text_hic_map/{nom}.q_{qval}.{binsize}.gi.nonchroms.tsv"
    threads: 1
    run:
        outhandle = open(output.hicm, "w")
        with open(input.hicm, "r") as f:
            for line in f:
                line = line.strip()
                if line:
                    fields = line.split()
                    s1 = True if fields[0] in config["chromosomes"] else False
                    s2 = True if fields[3] in config["chromosomes"] else False
                    printme = True
                    if s1 and s2:
                        printme = False
                    elif not s1 and not s2:
                        printme = False
                    if printme:
                        # this always prints the chromosome in the second column
                        if s1:
                            linemod = "\t".join([str(x) for x in [
                                 fields[3], fields[4], fields[5],
                                 fields[0], fields[1], fields[2], fields[6]
                                                                 ]])
                            print(linemod, file = outhandle)
                        elif s2:
                            print(line, file = outhandle)
                        else:
                            raise IOError("Shouldn't be here")

rule summarize_matrix_by_chromosome_coordinate:
    """
    Each scaffold must now be represented by a single value along the axis of
      chromosome coordinates.

    fields are:
      1: scaffold
      2: scaffold size
      3: chromosome
      4: chromosome start
      5; chromosome stop
      6: window_count
      7: rolling_window_count
      8: window area
      9: count_per_bases_squared
    """
    input:
        hicm = config["tool"] + "/output/{nom}/text_hic_map/{nom}.q_{qval}.{binsize}.gi.nonchroms.tsv",
        assem = config["tool"] + "/input/assembly/{nom}_input.fasta"
    output:
        hicm = config["tool"] + "/output/{nom}/text_hic_map/{nom}.q_{qval}.{binsize}.gi.nonchroms.best.tsv"
    threads: 1
    run:
        # first, get the scaffold to size
        scaf_to_size = {}
        with open(input.assem, "rU") as handle:
            for record in SeqIO.parse(handle, "fasta"):
                scaf_to_size[record.id] = len(record.seq)

        df = pd.read_csv(input.hicm, sep = "\t", header = None)
        df.columns = ["scaf", "start", "stop", "chrom", "cstart", "cstop", "count"]
        grouped_df = df.groupby(["scaf", "chrom", "cstart", "cstop"], as_index = False)["count"].sum()

        gb = grouped_df.groupby(["scaf", "chrom"], as_index = False)

        keeps = []
        for name, group in gb:
            # This makes a rolling window sum of the counts to get a more accurate
            #  estimate of the best position. It centers the value and sums up
            # 10 windows around it.
            pd.set_option('display.max_rows', 5000)
            group["window"] = group["count"].shift(-4).rolling(7).sum().fillna(0)
            temp = group.sort_values(["window", "count"], ascending = [False, False])
            keeps.append(temp.iloc[0])

        newdf = pd.DataFrame(keeps, columns=["scaf", "chrom", "cstart", "cstop", "count", "window"])
        newdf = newdf.reset_index(drop = True)

        # get the best chrom for each scaffold
        gb = newdf.groupby(["scaf"], as_index = False)
        keeps = []
        for name, group in gb:
            temp = group.sort_values(["window", "count"], ascending = [False, False])
            keeps.append(temp.iloc[0])

        newdf = pd.DataFrame(keeps, columns=["scaf", "chrom", "cstart", "cstop", "count", "window"])
        newdf = newdf.sort_values(["chrom", "cstart", "cstop"], ascending = [True, True, True])
        newdf = newdf.reset_index(drop = True)

        # modify each row
        newdf["scafsize"] = newdf["scaf"].map(scaf_to_size)
        newdf["area"] = 0
        newdf["count_per_MB_squared"] = 0
        for index, row in newdf.iterrows():
            thissize = row["scafsize"]
            if row["scafsize"] >= (7 * config["binsize"][0]):
                thissize = (7 * config["binsize"][0])
            thisarea = (thissize * config["binsize"][0])/1000000
            thiscount = row["window"] / thisarea
            newdf.loc[index, "area"] = thisarea
            newdf.loc[index, "count_per_bases_squared"] = thiscount

        newdf = newdf[["scaf", "scafsize", "chrom", "cstart", "cstop", "count",
                       "window", "area", "count_per_bases_squared"]]

        newdf.to_csv(output.hicm, sep = "\t", index = None)

class Chromosome:
    """
    This takes in a seqio record object
    """
    def __init__(self, record, min_gap_len, new_gap_length):
        self.new_gap_length = new_gap_length
        self.min_gap_len    = 10
        self.min_gap        = "".join(self.min_gap_len * ["N"])
        self.name           = record.name
        self.contig_ranges  = self.contig_ranges(str(record.seq).replace("n", "N"),
                                                 self.min_gap)
        self.contigs        = [str(record.seq[start:stop]) for start, stop in self.contig_ranges]
        self.inserts        = {}
        self.insertscopy    = {}
        # These are SeqIO records.
        #  They are just printed out in the order they are added.
        self.non_inserted_scafs = []
        # These are things that come out after we print
        self.new_contigs    = []
        self.chromosome_seq = ""
        self.SeqRecord = None

    def gen_chrom(self):
        """
        returns a string of the scaffold
        """
        self.insertscopy = {key: self.inserts[key] for key in self.inserts}

        thisseq = []
        for i in range(len(self.contig_ranges)):
            # get all the scaffolds that have their best match up until the middle
            #  of the scaffold
            #print(self.contig_ranges[i])
            max_front = (((self.contig_ranges[i][1] - self.contig_ranges[i][0])/2) + self.contig_ranges[i][0]) + 1
            del_these = []
            for key in self.inserts:
                if key < max_front:
#                    print("found something ", key)
                    for seq in self.inserts[key]:
                        thisseq.append(seq)
                    del_these.append(key)
            for del_this in del_these:
                del self.inserts[del_this]

            # now add the chromosome contig
            thisseq.append(self.contigs[i])

            # now add the scaffolds that map from the middle to the end of the contig
            max_front = self.contig_ranges[i][1] + 1
            del_these = []
            for key in self.inserts:
                if key < max_front:
#                    print("found something2 ", key)
                    for seq in self.inserts[key]:
                        thisseq.append(seq)
                    del_these.append(key)
            for del_this in del_these:
                del self.inserts[del_this]

            # if we're at the end, just add everything else to the scaffold
            del_these = []
            if i == len(self.contig_ranges):
                for key in self.inserts:
#                    print("found something3 ", key)
                    for seq in self.inserts[key]:
                        thisseq.append(seq)
                    del_these.append(key)
            for del_this in del_these:
                del self.inserts[del_this]

        # make sure that we've handled all the inserts
        if len(self.inserts) > 0:
            print(["{} {}".format(k,len(self.inserts[k])) for k in self.inserts])
            raise IOError("We didn't insert all of the scaffolds into the chrom")

        self.new_contigs = thisseq
        gapseq = "".join(["N"] * self.new_gap_length)
        self.chromosome_seq = gapseq.join(self.new_contigs)

        # copy
        self.inserts = {key: self.insertscopy[key] for key in self.insertscopy}
        self.SeqRecord = SeqRecord(Seq(self.chromosome_seq), id=self.name)

    def insert(self, seq, best_loc):
        if best_loc not in self.inserts:
            self.inserts[best_loc] = []
        self.inserts[best_loc].append( seq )

    def append(self, record):
        self.non_inserted_scafs.append(record)

    def contig_ranges(self, seq, sub):
        indices = list(self.find_all(seq, sub))
        gap_starts = []
        gap_stops  = []
        gap_ranges = []
        prev = -1

        # get the starts of the gaps
        for i in range(len(indices)):
            if prev != indices[i] - 1:
                gap_starts.append(indices[i])
            prev = indices[i]

        # get the indices of the ends of the gaps
        prev = 999999999999
        for i in range(len(indices) - 1, -1, -1):
            if prev != indices[i] + 1:
                gap_stops.append(indices[i])
            prev = indices[i]
        gap_stops = [x + len(sub) for x in gap_stops[::-1]]

        contigs = []
        # now get the ranges
        for i in range(len(gap_stops)):
            gap_ranges.append([gap_starts[i], gap_stops[i]])
            if i == 0:
                contigs.append([0, gap_starts[i]])
                contigs.append([gap_stops[i], gap_starts[i+1]])
            elif i == (len(gap_stops) -1):
                contigs.append([gap_stops[i], len(seq)])
            else:
                contigs.append([gap_stops[i], gap_starts[i+1]])
        return contigs

    def find_all(self, seq, sub):
        """
        https://stackoverflow.com/questions/4664850/how-to-find-all-occurrences-of-a-substring
        """
        start = 0
        indices = []
        while True:
            start = seq.find(sub, start)
            if start == -1: return
            yield start
            #start += len(sub) # use start += 1 to find overlapping matches
            start += 1 # use start += 1 to find overlapping matches
        return indices


rule output_sorted_fasta:
    """
    Outputs a new fasta file with the scaffolds sorted by best
     chromosome position
    """
    input:
        hicm  = config["tool"] + "/output/{nom}/text_hic_map/{nom}.q_{qval}.{binsize}.gi.nonchroms.best.tsv",
        assem = config["tool"] + "/input/assembly/{nom}_input.fasta"
    output:
        assem = config["tool"] + "/output/assembly/{nom}_q_{qval}_{binsize}_output.fasta"
    params:
        strength_fraction = config["strength_fraction"],
        min_insert_size   = config["min_insert_size"],
        new_gap_length    = config["new_gap_length"]
    threads: 1
    run:
        # put the record objects into a dictionary
        chrom_order        = [x for x in config["chromosomes"]]
        unseen_chromosomes = list(set([x for x in config["chromosomes"]]))
        unseen_scafs       = []
        if len(chrom_order) != len(unseen_chromosomes):
            raise IOError("You accidentally put duplicate chromosomes into the config")

        chromosome_dict  = {}
        scaffold_dict    = {}
        scaffold_order   = []
        with open(input.assem, "rU") as handle:
            for record in SeqIO.parse(handle, "fasta"):
                if record.id in config["chromosomes"]:
                    unseen_chromosomes.remove(str(record.id))
                    chromosome_dict[record.id] = Chromosome(record, 10, params.new_gap_length)
                else:
                    scaffold_dict[record.id] = record
                    scaffold_order.append(record.id)
                    unseen_scafs.append(record.id)

        # potentially an error here. Read this message
        if len(unseen_chromosomes) > 0:
            raise IOError("You specified these chromosomes but they were not in the fasta file: {}".format(unseen_chromosomes))


        # read in the scafs
        df = pd.read_csv(input.hicm, sep = "\t")
        # get the quantile
        min_strength = float(df["count_per_bases_squared"].quantile(1 - params.strength_fraction))

        # These contigs we insert into the chromosomes
        insert_df = df.loc[((df["count_per_bases_squared"] >= min_strength) & \
                            (df["scafsize"] >= params.min_insert_size)), ]
        append_df = df.loc[~((df["count_per_bases_squared"] >= min_strength) & \
                             (df["scafsize"] >= params.min_insert_size)), ]
        insert_df.reset_index(drop = True, inplace = True)
        append_df.reset_index(drop = True, inplace = True)

        # These contigs we insert into the scaffold to be printed in between
        #  the other scaffolds
        for index, row in insert_df.iterrows():
            this_seq = str(scaffold_dict[row["scaf"]].seq)
            chromosome_dict[row["chrom"]].insert(this_seq, row["cstop"])
            del scaffold_dict[row["scaf"]]
            scaffold_order.remove(row["scaf"])
            unseen_scafs.remove(row["scaf"])

        # These are the scaffolds that will be printed out later
        for index, row in append_df.iterrows():
            chromosome_dict[row["chrom"]].append(scaffold_dict[row["scaf"]])
            del scaffold_dict[row["scaf"]]
            scaffold_order.remove(row["scaf"])
            unseen_scafs.remove(row["scaf"])

        # Should be safe to move forward now
        outhandle = open(output.assem, "w")
        # now print out the chromosomes
        for thischrom in chrom_order:
            print("printing ", thischrom)
            chromosome_dict[thischrom].gen_chrom()
            SeqIO.write(chromosome_dict[thischrom].SeqRecord, outhandle, "fasta")
        # now write the other scaffolds
        for thischrom in chrom_order:
            for thisscaf in chromosome_dict[thischrom].non_inserted_scafs:
                SeqIO.write(thisscaf, outhandle, "fasta")
                try:
                    unseen_scafs.remove(thisscaf.id)
                except:
                    pass
        # now write the scaffolds that didn't have any Hi-C connections to anything
        for thisscaf in unseen_scafs:
            SeqIO.write(scaffold_dict[thisscaf], outhandle, "fasta")
        outhandle.close()
