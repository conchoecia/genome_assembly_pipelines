"""
This snakefile maps all the HiC reads to a final genome assembly
  - It also makes a pretextmap file for quickly looking at the hic-maps
  - It also calculates the obs/exp matrix, and the pearson exp matrix of that
"""
from Bio import SeqIO
minchromsize = 1000000
configfile: "config.yaml"


def get_chromosome_sizes(assembly_file, minsize):
    """
    returns a set of chromosomes to keep
    """
    chroms = []
    with open(assembly_file) as handle:
        for record in SeqIO.parse(handle, "fasta"):
            if len(record.seq) >= minsize:
                chroms.append(record.id)
    return chroms


config["tool"] = "GAP_hic_map3"

rule all:
    input:
        #stats - this is in the pair processing step. fine with HiC-v2
        expand(config["tool"] + "/output/pairsam_stats/{nom}_parsed.pairsam.stats",
               nom = config["assemblies"]),
        expand(config["tool"] + "/output/pairsam_stats/{nom}_parsed_sorted_dedupe.pairsam.stats",
               nom = config["assemblies"]),

        #final files
        # chromsize
        expand(config["tool"] + "/output/{nom}/{nom}_chromsize.txt",
               nom = config["assemblies"]),
        # gaps
        expand(config["tool"] + "/output/{nom}/{nom}_gaps.bed",
               nom = config["assemblies"]),
        # get the diagnostic png before doing anything else
        expand(config["tool"] + "/output/{nom}/{nom}.{binsize}.cool.png",
               nom = config["assemblies"], binsize=config["binsize"]),
        # balanced cool
        expand(config["tool"] + "/output/{nom}/{nom}_balanced.{binsize}.cool",
               nom = config["assemblies"], binsize=config["binsize"]),
        # mcool from balanced
        expand(config["tool"] + "/output/{nom}/{nom}_balanced.{binsize}.mcool",
               nom = config["assemblies"], binsize=config["binsize"]),
        ## pretext view
        expand(config["tool"] + "/output/{nom}/{nom}.pretext", nom = config["assemblies"]),
        # plots of AB compartmentalization
        expand(config["tool"] + "/output/{nom}/ABcompartments/{nom}_balanced.{binsize}.onlychr.obsexplieb.pearson.plot.pdf", nom = config["assemblies"], binsize = [x for x in config["binsize"] if int(x) >= 50000])

        ## output interaction matrix used for running the Lorentz 3DGR problem
        #expand(config["tool"] + "/output/{nom}/3DGR/{nom}_balanced.{binsize}.if.tsv",
        #       nom = config["assemblies"], binsize=config["binsize"]),

# make softlinks of the input files
# files end up here:
#   assem = config["tool"] + "/input/assembly/{nom}_input.fasta",
filepath = os.path.dirname(os.path.realpath(workflow.snakefile))
softlinks_rule_path=os.path.join(filepath, "snakemake_includes/assembly_softlinks")
include: softlinks_rule_path

rule chrom_size:
    """
    make a file with the chromosome sizes
    """
    input:
        assem = config["tool"] + "/input/assembly/{nom}_input.fasta"
    output:
        cs = config["tool"] + "/output/{nom}/{nom}_chromsize.txt"
    threads: 1
    shell:
        """
        bioawk -cfastx '{{printf("%s\\t%d\\n", $name, length($seq))}}' {input.assem} > {output.cs}
        """

rule index_ref:
    input:
        assem = config["tool"] + "/input/assembly/{nom}_input.fasta"
    output:
        amb   = config["tool"] + "/input/assembly/{nom}_input.fasta.amb",
        ann   = config["tool"] + "/input/assembly/{nom}_input.fasta.ann",
        bwt   = config["tool"] + "/input/assembly/{nom}_input.fasta.bwt",
        pac   = config["tool"] + "/input/assembly/{nom}_input.fasta.pac",
    shell:
        """
        bwa index {input.assem}
        """

rule gaps_from_assembly:
    input:
        assem = config["tool"] + "/input/assembly/{nom}_input.fasta",
    output:
        gapbed = config["tool"] + "/output/{nom}/{nom}_gaps.bed"
    threads: 1
    run:
        # this block of code from https://www.biostars.org/p/133742/
        import sys
        #import the SeqIO module from Biopython
        outhandle = open(output.gapbed, "w")
        with open(input.assem, mode="r") as fasta_handle:
            for record in SeqIO.parse(fasta_handle, "fasta"):
                start_pos=0
                counter=0
                gap=False
                gap_length = 0
                for char in record.seq:
                    if char == 'N':
                        if gap_length == 0:
                            start_pos=counter
                            gap_length = 1
                            gap = True
                        else:
                            gap_length += 1
                    else:
                        if gap:
                            print("{}\t{}\t{}".format(
                                record.id,
                                start_pos,
                                start_pos + gap_length),
                                  file = outhandle)
                            gap_length = 0
                            gap = False
                    counter += 1
        outhandle.close()

rule map_hic_to_ref:
    input:
        assem = config["tool"] + "/input/assembly/{nom}_input.fasta",
        amb   = config["tool"] + "/input/assembly/{nom}_input.fasta.amb",
        ann   = config["tool"] + "/input/assembly/{nom}_input.fasta.ann",
        bwt   = config["tool"] + "/input/assembly/{nom}_input.fasta.bwt",
        pac   = config["tool"] + "/input/assembly/{nom}_input.fasta.pac",
        left  = lambda wildcards: config["libs"][wildcards.lib]["read1"],
        right = lambda wildcards: config["libs"][wildcards.lib]["read2"]
    output:
        bam   = config["tool"] + "/input/bams/{nom}_{lib}_to_ref.sorted.bam"
    threads:
        workflow.cores
    shell:
        """
        # DONT PIPE INTO SAMTOOLS SORT
        bwa mem -5SPM -t {threads} {input.assem} {input.left} {input.right} | \
            samtools view -hb -@ {threads} - > {output.bam}
        # DO NOT PIPE INTO SAMTOOLS SORT
        """

rule hic_make_pairsam:
    """
    # BAM to pairs: annotate reads, create a pairsam file
    """
    input:
        bam   = expand(config["tool"] + "/input/bams/{{nom}}_{lib}_to_ref.sorted.bam", lib=config["libs"]),
        cs = config["tool"] + "/output/{nom}/{nom}_chromsize.txt"
    output:
        ps = config["tool"] + "/output/temp/pairsam/{nom}_parsed.pairsam.gz",
        stats = config["tool"] + "/output/pairsam_stats/{nom}_parsed.pairsam.stats"
    threads: 1
    shell:
        """
        NUMBAM=$(echo "{input.bam}" | sed 's/ /\\n/g' | wc -l)
        if [ ${{NUMBAM}} -gt 1 ]
          then
            samtools cat -h {input.bam} | samtools view -h - | \
              pairtools parse --output-stats {output.stats} \
              -c {input.cs} -o {output.ps}
          else
            samtools view -h {input.bam} | \
              pairtools parse --output-stats {output.stats} \
              -c {input.cs} -o {output.ps}
        fi
        """

rule hic_sort_pairsam:
    """
    Sorting pairs by chromosome1-chromosome2-position1-position2
    <n_proc> = number of processors to be used
    """
    input:
        ps = config["tool"] + "/output/temp/pairsam/{nom}_parsed.pairsam.gz"
    output:
        pps = config["tool"] + "/output/temp/sorted/{nom}_parsed_sorted.pairsam.gz"
    threads:
        workflow.cores - 1
    shell:
        """
        pairtools sort --nproc {threads} -o {output.pps} {input.ps} --tmpdir=./
        """

rule hic_dedup:
    """
    # NOTE: this step needs to write a lot of tmp files,
      and by default your tmp directory is in your home directory,
      which can fill up. To avoid that, do this before running the sort command:

     # Marking duplicates
     # <n_proc> = number of processors to be used
    """
    input:
        pps = config["tool"] + "/output/temp/sorted/{nom}_parsed_sorted.pairsam.gz"
    output:
        dpps = config["tool"] + "/output/temp/dedupe/{nom}_parsed_sorted_dedupe.pairsam.gz",
        stats = config["tool"] + "/output/pairsam_stats/{nom}_parsed_sorted_dedupe.pairsam.stats"
    threads:
        workflow.cores - 1
    params:
        nom = lambda w: w.nom
    shell:
        """
        mkdir -p tempdir{params.nom}
        export TMPDIR=tempdir{params.nom}
        pairtools dedup --nproc-in {threads} \
          --output-stats {output.stats} \
          --mark-dups -o {output.dpps} {input.pps}
        rm -rf tempdir{params.nom}
        """

rule hic_filter:
    input:
        dpps = config["tool"] + "/output/temp/dedupe/{nom}_parsed_sorted_dedupe.pairsam.gz",
    output:
        filt = config["tool"] + "/output/temp/filt/{nom}_parsed_sorted_dedupe_filt.pairsam.gz"
    threads:
        1
    shell:
        """
        pairtools select  '(pair_type == "UU") or (pair_type == "UR") or (pair_type == "RU")' \
          -o {output.filt} {input.dpps}
        """

rule generate_final_pairs:
    """
    generate the final output from a pairsam to a pairs file
    """
    input:
        filt = config["tool"] + "/output/temp/filt/{nom}_parsed_sorted_dedupe_filt.pairsam.gz"
    output:
        final = config["tool"] + "/output/pairs/{nom}/{nom}.dedup.filt.pairs.gz"
    threads:
        1
    shell:
        """
        pairtools split --output-pairs {output.final} {input.filt}
        """

rule index_pairs:
    """
    indexing output. the *.pairs.gz suffix is important to parse the file correctly!
    """
    input:
        pairs = config["tool"] + "/output/pairs/{nom}/{nom}.dedup.filt.pairs.gz"
    output:
        index = config["tool"] + "/output/pairs/{nom}/{nom}.dedup.filt.pairs.gz.px2"
    threads:
        1
    shell:
        """
        pairix -f {input.pairs}
        """

rule make_bins_individual:
    """
    This makes the matrix and bins everything
    i.e. binsize: 5000 (high resolution), 500000 (lower resolution)
    """
    input:
        final = config["tool"] + "/output/pairs/{nom}/{nom}.dedup.filt.pairs.gz",
        index = config["tool"] + "/output/pairs/{nom}/{nom}.dedup.filt.pairs.gz.px2",
        cs = config["tool"] + "/output/{nom}/{nom}_chromsize.txt"
    output:
        cool = config["tool"] + "/output/{nom}/{nom}.{binsize}.cool"
    threads:
        1
    params:
        bs = lambda wildcards: wildcards.binsize,
        nom = lambda wildcards: wildcards.nom,
        outname = lambda wildcards: "{tool}/output/{nom}/{nom}.{binsize}.cool".format(
            tool=config["tool"], nom = wildcards.nom, binsize = wildcards.binsize )
    shell:
        """
        cooler cload pairix {input.cs}:{params.bs} {input.final} {params.outname}
        """

rule diagnostic_plot:
    """
    This generates a diagnostic plot of the bin distribution to pick the z-score cutoffs
    """
    input:
        cool = config["tool"] + "/output/{nom}/{nom}.{binsize}.cool"
    output:
        png = config["tool"] + "/output/{nom}/{nom}.{binsize}.cool.png"
    shell:
        """
        hicCorrectMatrix diagnostic_plot -m {input.cool} -o {output.png}
        """

rule cutoff_matrix:
    """
    Balances the matrix using the z-score cutoffs. Removes bins that are too dense or sparse
    """
    input:
        png = config["tool"] + "/output/{nom}/{nom}.{binsize}.cool.png",
        cool = config["tool"] + "/output/{nom}/{nom}.{binsize}.cool"
    output:
        balanced = config["tool"] + "/output/{nom}/{nom}_balanced.{binsize}.cool"
    params:
        zmin = lambda wildcards: config["binsize"][int(wildcards.binsize)]["zmin"],
        zmax = lambda wildcards: config["binsize"][int(wildcards.binsize)]["zmax"],
        binsize = lambda wildcards: wildcards.binsize
    shell:
        """
        if [ "{params.zmin}" -eq "0" ]; then
            echo "Set the {params.binsize} zmin to something other than 0";
            exit;
        fi
        if [ "{params.zmin}" -eq "0" ]; then
            echo "Set the {params.binsize} zmax to something other than 0";
            exit;
        fi
        hicCorrectMatrix correct -m {input.cool} \
             --filterThreshold {params.zmin} {params.zmax} \
             -o {output.balanced}
        """

#rule old_balance_matrix:
#    """
#    ## Matrix normalization/ balancing
#    #cooler balance res.<binsize>.cool
#    ## if any problems with creating output add "--force" option
#    # this only works with --cis-only. Otherwise it drops a ton of bins
#    """
#    input:
#        cool = config["tool"] + "/output/{nom}/{nom}.{binsize}.cool"
#    output:
#        cool = config["tool"] + "/output/{nom}/{nom}_balanced.{binsize}.cool"
#    shell:
#        """
#        cp {input.cool} {output.cool}
#        cooler balance --force {output.cool}
#        """

rule zoomify_matrix:
    """
    ## Aggregation (for HiGlass view) - This generates a *.mcool file from the balanced cool file
    """
    input:
        cool = config["tool"] + "/output/{nom}/{nom}_balanced.{binsize}.cool"
    output:
        mcool = config["tool"] + "/output/{nom}/{nom}_balanced.{binsize}.mcool"
    shell:
        """
        cooler zoomify -o {output.mcool} {input.cool}
        """

# Filter out the small chromosomes for further analyses/balancing/et cet
rule only_chromosomes:
    input:
        cool = config["tool"] + "/output/{nom}/{nom}_balanced.{binsize}.cool",
        assem = config["tool"] + "/input/assembly/{nom}_input.fasta"
    output:
        onlychr = config["tool"] + "/output/{nom}/ABcompartments/{nom}_balanced.{binsize}.onlychr.cool"
    params:
        mc = minchromsize
        #chr_string = lambda wildcards: ' '.join(get_chromosome_sizes(
        #                      config["tool"] + "/input/assembly/{}_input.fasta".format(wildcards.nom), 
        #                      minchromsize))
    shell:
        """
        CHROMS=$(bioawk -cfastx '{{if (length($seq) >= {params.mc}) {{printf("%s ", $name)}} }}' {input.assem})
        >&2 echo "keeping ${{CHROMS}}"
        hicAdjustMatrix --chromosomes ${{CHROMS}} \
             -m {input.cool} \
             --outFileName {output.onlychr} \
             --action keep
        """

# Now compute the obs-exp using lieberman-aiden
rule obs_expected_lieb:
    input:
        onlychr = config["tool"] + "/output/{nom}/ABcompartments/{nom}_balanced.{binsize}.onlychr.cool"
    output:
        obsexp = config["tool"] + "/output/{nom}/ABcompartments/{nom}_balanced.{binsize}.onlychr.obsexplieb.cool"
    shell:
        """
        hicTransform -m {input.onlychr} \
             --outFileName {output.obsexp} \
             --method obs_exp_lieberman
        """

# Now compute the Pearson matrix of the obs-exp. Plotting this shows A-B compartments
rule pearson_matrix:
    input:
        obsexp = config["tool"] + "/output/{nom}/ABcompartments/{nom}_balanced.{binsize}.onlychr.obsexplieb.cool"
    output:
        pearson = config["tool"] + "/output/{nom}/ABcompartments/{nom}_balanced.{binsize}.onlychr.obsexplieb.pearson.cool"
    shell:
        """
        hicTransform -m {input.obsexp} \
             --outFileName {output.pearson} \
             --method pearson
        """

# Calculates the obs/exp of the matrix
rule PCA_of_matrix:
    """
    this makes a bigwig file of the PCAs of the balanced cooler files
    """
    input:
        onlychr = config["tool"] + "/output/{nom}/ABcompartments/{nom}_balanced.{binsize}.onlychr.cool"
    output:
        pca1 = config["tool"] + "/output/{nom}/ABcompartments/{nom}_balanced.{binsize}.onlychr.pca1.bw",
        pca2 = config["tool"] + "/output/{nom}/ABcompartments/{nom}_balanced.{binsize}.onlychr.pca2.bw"
    threads: 1
    shell:
        """
        hicPCA -m {input.cool} -o {output.pca1} {output.pca2} --format bigwig
        """

rule plot_matrices:
    input:
        pearson = config["tool"] + "/output/{nom}/ABcompartments/{nom}_balanced.{binsize}.onlychr.obsexplieb.pearson.cool",
        pca1 = config["tool"] + "/output/{nom}/ABcompartments/{nom}_balanced.{binsize}.pca1.bw"
    output:
        pdf = config["tool"] + "/output/{nom}/ABcompartments/{nom}_balanced.{binsize}.ABplot.pdf"
    threads: 1
    shell:
        """
        hicPlotMatrix --colorMap RdBu -m {input.pearson} --outFileName {output.pdf} --perChr --bigwig {input.pca1}
        """

rule convert_pearson_to_gi:
    """
    converts the pearson correlation matrix to a gi file. This is easier to work with than a cooler file.
    """
    input:
        pearson = config["tool"] + "/output/{nom}/ABcompartments/{nom}_balanced.{binsize}.onlychr.obsexplieb.pearson.cool"
    output:
        gi = config["tool"] + "/output/{nom}/ABcompartments/{nom}_balanced.{binsize}.onlychr.obsexplieb.pearson.gi.tsv"
    params:
        gi = config["tool"] + "/output/{nom}/ABcompartments/{nom}_balanced.{binsize}.onlychr.obsexplieb.pearson.gi"
    shell:
        """
        hicConvertFormat -m {input.pearson} \
           --outFileName {params.gi} \
           --inputFormat cool \
           --outputFormat ginteractions
        """

rule plot_matrices_custom:
    """
    This plots the AB compartments using a custom script.
    I think the results are much nicer than the package that is included in HiCExplorer
    """
    input:
        gi = config["tool"] + "/output/{nom}/ABcompartments/{nom}_balanced.{binsize}.onlychr.obsexplieb.pearson.gi.tsv"
    output:
        pdf = config["tool"] + "/output/{nom}/ABcompartments/{nom}_balanced.{binsize}.onlychr.obsexplieb.pearson.plot.pdf"
    run:
        import ast
        import pandas as pd
        import seaborn as sns; sns.set()
        import matplotlib
        import matplotlib.pyplot as plt
        import matplotlib.ticker as ticker
        from matplotlib.backends.backend_pdf import PdfPages
        from matplotlib.ticker import StrMethodFormatter, NullFormatter
        import numpy as np

        # set seaborn stuff
        #sns.set(rc={'text.usetex' : True})
        sns.set_style("ticks", {'font.family': ['sans-serif'],
                                    'font.sans-serif': ['Helvetica'],
                                    'grid.color': '.95'})

        # Preserve the vertical order of embedded images:
        matplotlib.rcParams['image.composite_image'] = False
        matplotlib.rcParams['pdf.fonttype'] = 42
        matplotlib.rcParams['ps.fonttype'] = 42

        # plot all the whole chromosome interactions
        filepath = input.gi

        # set up the pdf to which we will save everything
        outfile = output.pdf
        pp = PdfPages(outfile)

        dfs = []
        columns = [["source", "sstart", "sstop",
                      "target", "tstart", "tstop",
                      "counts"],
                   ["target", "tstart", "tstop",
                   "source", "sstart", "sstop",
                   "counts"]]

        for i in range(2):
            df = pd.read_csv(filepath, header=None, sep='\t')
            df.columns = columns[i]
            #df["distance"] = df["tstart"] - df["sstart"]
            #expected = df.groupby(["distance"]).mean().reset_index()
            #expected["expected"] = expected["counts"]
            #expected = expected[["distance", "expected"]]
            #df = df.merge(expected, left_on='distance', right_on='distance')
            #df["log_obs_exp"] = np.log2(df["counts"]/df["expected"])
            #df["source"] = df.apply(lambda row: ''.join(i for i in row["source"] if i.isdigit()), axis =1)
            #df["target"] = df.apply(lambda row: ''.join(i for i in row["target"] if i.isdigit()), axis =1)
            #df["source"] = df.apply(lambda row: ''.join(row["source"].str.replace("Chr", "").replace("chr", "").replace("c",""), axis =1))
            #df["target"] = df.apply(lambda row: ''.join(row["target"].str.replace("Chr", "").replace("chr", "").replace("c",""), axis =1))
            #df["source"] = df.apply(lambda row: row["source"].str.replace("Chr", ""), axis =1)
            #df["target"] = df.apply(lambda row: row["target"].str.replace("Chr", ""), axis =1)   
            for deletethis in ["Chr", "chr", "c"]:
                df["source"] = df["source"].str.replace(deletethis, "")
                df["target"] = df["target"].str.replace(deletethis, "")
            dfs.append(df)

        concat = pd.concat(dfs).reset_index()
        concat = concat[[x for x in concat.columns if x != "index"]]

        #first, just read in the the dataframe to get all of the chromosomes
        chroms = list(concat["target"].unique())

        directorypath = output.pdf.replace(".pdf", "")
        if not os.path.exists(directorypath):
            os.mkdir(directorypath)

        for middle in ["dark", "light"]:
            for thischrom in chroms:
                missing_rows = []
                onechrom = concat.loc[concat["source"] == concat["target"], ]
                onechrom = onechrom.loc[onechrom["source"] == thischrom, ]
                #figure out the interval
                interval = (onechrom["sstop"] - onechrom["sstart"]).value_counts().idxmax()
                minstart = onechrom["sstart"].min()
                maxstart = onechrom["sstart"].max()
                #now go through and find missing rows
                has_these_starts_set = set(onechrom["sstart"].unique())
                should_have_all_these_starts_set = set(np.arange(minstart,maxstart+interval,interval))
                needs_these_rows = sorted(list(should_have_all_these_starts_set.difference(has_these_starts_set)))
                #manually add the rows to the missing_rows_list
                for i in range(len(needs_these_rows)):
                    for j in range(len(needs_these_rows)):
                        missing_rows.append({"source": thischrom,
                                             "sstart": needs_these_rows[i],
                                             "sstop":  needs_these_rows[i] + interval,
                                             "target": thischrom,
                                             "tstart": needs_these_rows[j],
                                             "tstop":  needs_these_rows[j] + interval,
                                             "counts": np.nan
                                            })
                tempdf = pd.DataFrame.from_dict(missing_rows)
                plot_concat = pd.concat([onechrom, tempdf]).reset_index(drop=True)
                plot_concat["tstart"] = plot_concat["tstart"]/1000000
                plot_concat["sstart"] = plot_concat["sstart"]/1000000
                result = plot_concat.pivot_table(index='tstart',
                                        columns='sstart',
                                        values='counts', dropna=False)
                #result.columns.name = None
                ax = sns.heatmap(result,
                                 cmap = sns.diverging_palette(256, 0, n=100, center=middle), 
                                 square=True,
                                 mask=result.isnull(),
                                 linewidths=0.0)
                ax.set_title("Hi-C Obs/Exp Pearson - Chr {}".format(thischrom))
                ax.set_ylabel("Position (Mb)")
                ax.set_xlabel("Position (Mb)")
                fig = ax.get_figure()
                fig.tight_layout()
                pngpath = directorypath + "/plot_of_{}.{}.{}.png".format(thischrom, interval, middle)
                print("Saving the file: {}".format(pngpath))
                fig.savefig(pngpath, dpi=300)
                pp.savefig()
                fig.clear()
        pp.close()

## Now plot the gene interactions matrix
## get the list of chromosomes that we will keep for 3DGR
#
#rule gene_interactions_matrix:
#    input:
#        cool = config["tool"] + "/output/{nom}/{nom}_balanced.{binsize}.cool"
#    output:
#        giv = config["tool"] + "/output/{nom}/3DGR/{nom}_balanced.{binsize}.gi.tsv"
#    params:
#        giv = lambda w: config["tool"] + "/output/{nom}/3DGR/{nom}_balanced.{binsize}.gi".format(
#               nom = w.nom, binsize = w.binsize)
#    threads: 1
#    shell:
#        """
#        hicConvertFormat -m {input.cool} -o {params.giv} \
#           --inputFormat cool --outputFormat ginteractions
#        """
#
#rule convert_gi_to_if:
#    """
#    This converts the gi to an interaction frequency matrix used by LorDB
#    """
#    input:
#        giv = config["tool"] + "/output/{nom}/3DGR/{nom}_balanced.{binsize}.gi.tsv",
#        gi_to_if_script = os.path.join(filepath, "gi_to_if.py")
#    output:
#        giv = config["tool"] + "/output/{nom}/3DGR/{nom}_balanced.{binsize}.if.tsv"
#    threads: 1
#    shell:
#        """
#        cat {input.giv} | python {input.gi_to_if_script} > {output.giv}
#        """

# This part makes a pretext map
rule make_pretextmap:
    input:
        bam   = expand(config["tool"] + "/input/bams/{{nom}}_{lib}_to_ref.sorted.bam", lib=config["libs"]),
    output:
        pretext = config["tool"] + "/output/{nom}/{nom}.pretext"
    threads: 1
    shell:
        """
        NUMBAM=$(echo "{input.bam}" | sed 's/ /\\n/g' | wc -l)
        if [ ${{NUMBAM}} -gt 1 ]
          then
            samtools cat -h {input.bam} | samtools view -h - | \
                PretextMap -o {output.pretext}
          else
            samtools view -h {input.bam} | \
                PretextMap -o {output.pretext}
        fi
        """
