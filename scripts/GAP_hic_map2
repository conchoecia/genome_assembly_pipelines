"""
This snakefile maps all the HiC reads to a final genome assembly
  - It also makes a pretextmap file for quickly looking at the hic-maps
"""
configfile: "config.yaml"
config["tool"] = "GAP_hic_map"

rule all:
    input:
        #stats - this is in the pair processing step. fine with HiC-v2
        expand(config["tool"] + "/output/pairsam_stats/{nom}_parsed.pairsam.stats",
               nom = config["assemblies"]),
        expand(config["tool"] + "/output/pairsam_stats/{nom}_parsed_sorted_dedupe.pairsam.stats",
               nom = config["assemblies"]),

        #final files
        # chromsize
        expand(config["tool"] + "/output/{nom}/{nom}_chromsize.txt", nom = config["assemblies"]),
        # balanced cool
        expand(config["tool"] + "/output/{nom}/{nom}_balanced.{binsize}.cool",
               nom = config["assemblies"], binsize=config["binsize"]),
        # mcool from balanced
        expand(config["tool"] + "/output/{nom}/{nom}_balanced.{binsize}.mcool",
               nom = config["assemblies"], binsize=config["binsize"]),
        # pretext view
        expand(config["tool"] + "/output/{nom}/{nom}.pretext", nom = config["assemblies"]),
        # pca files
        expand(config["tool"] + "/output/{nom}/ABcompartments/{nom}_balanced.{binsize}.ABplot.pdf",
               nom = config["assemblies"], binsize=config["binsize"]),
        ## output interaction matrix used for running the Lorentz 3DGR problem
        #expand(config["tool"] + "/output/{nom}/3DGR/{nom}_balanced.{binsize}.if.tsv",
        #       nom = config["assemblies"], binsize=config["binsize"]),

# make softlinks of the input files
# files end up here:
#   assem = config["tool"] + "/input/assembly/{nom}_input.fasta",
filepath = os.path.dirname(os.path.realpath(workflow.snakefile))
softlinks_rule_path=os.path.join(filepath, "snakemake_includes/assembly_softlinks")
include: softlinks_rule_path

rule chrom_size:
    """
    make a file with the chromosome sizes
    """
    input:
        assem = config["tool"] + "/input/assembly/{nom}_input.fasta"
    output:
        cs = config["tool"] + "/output/{nom}/{nom}_chromsize.txt"
    threads: 1
    shell:
        """
        bioawk -cfastx '{{printf("%s\\t%d\\n", $name, length($seq))}}' {input.assem} > {output.cs}
        """

rule index_ref:
    input:
        assem = config["tool"] + "/input/assembly/{nom}_input.fasta"
    output:
        amb   = config["tool"] + "/input/assembly/{nom}_input.fasta.amb",
        ann   = config["tool"] + "/input/assembly/{nom}_input.fasta.ann",
        bwt   = config["tool"] + "/input/assembly/{nom}_input.fasta.bwt",
        pac   = config["tool"] + "/input/assembly/{nom}_input.fasta.pac",
    shell:
        """
        bwa index {input.assem}
        """

rule map_hic_to_ref:
    input:
        assem = config["tool"] + "/input/assembly/{nom}_input.fasta",
        amb   = config["tool"] + "/input/assembly/{nom}_input.fasta.amb",
        ann   = config["tool"] + "/input/assembly/{nom}_input.fasta.ann",
        bwt   = config["tool"] + "/input/assembly/{nom}_input.fasta.bwt",
        pac   = config["tool"] + "/input/assembly/{nom}_input.fasta.pac",
        left  = lambda wildcards: config["libs"][wildcards.lib]["read1"],
        right = lambda wildcards: config["libs"][wildcards.lib]["read2"]
    output:
        bam   = config["tool"] + "/input/bams/{nom}_{lib}_to_ref.sorted.bam"
    threads:
        workflow.cores
    shell:
        """
        # DONT PIPE INTO SAMTOOLS SORT
        bwa mem -5SPM -t {threads} {input.assem} {input.left} {input.right} | \
            samtools view -hb -@ {threads} - > {output.bam}
        # DO NOT PIPE INTO SAMTOOLS SORT
        """

rule hic_make_pairsam:
    """
    # BAM to pairs: annotate reads, create a pairsam file
    """
    input:
        bam   = expand(config["tool"] + "/input/bams/{{nom}}_{lib}_to_ref.sorted.bam", lib=config["libs"]),
        cs = config["tool"] + "/output/{nom}/{nom}_chromsize.txt"
    output:
        ps = config["tool"] + "/output/temp/pairsam/{nom}_parsed.pairsam.gz",
        stats = config["tool"] + "/output/pairsam_stats/{nom}_parsed.pairsam.stats"
    threads: 1
    shell:
        """
        samtools cat -h {input.bam} | samtools view -h - | \
          pairtools parse --output-stats {output.stats} \
          -c {input.cs} -o {output.ps}
        """

rule hic_sort_pairsam:
    """
    Sorting pairs by chromosome1-chromosome2-position1-position2
    <n_proc> = number of processors to be used
    """
    input:
        ps = config["tool"] + "/output/temp/pairsam/{nom}_parsed.pairsam.gz"
    output:
        pps = config["tool"] + "/output/temp/sorted/{nom}_parsed_sorted.pairsam.gz"
    threads:
        max(workflow.cores/9, 9)
    shell:
        """
        pairtools sort --nproc {threads} -o {output.pps} {input.ps} --tmpdir=./
        """

rule hic_dedup:
    """
    # NOTE: this step needs to write a lot of tmp files,
      and by default your tmp directory is in your home directory,
      which can fill up. To avoid that, do this before running the sort command:

     # Marking duplicates
     # <n_proc> = number of processors to be used
    """
    input:
        pps = config["tool"] + "/output/temp/sorted/{nom}_parsed_sorted.pairsam.gz"
    output:
        dpps = config["tool"] + "/output/temp/dedupe/{nom}_parsed_sorted_dedupe.pairsam.gz",
        stats = config["tool"] + "/output/pairsam_stats/{nom}_parsed_sorted_dedupe.pairsam.stats"
    threads:
        max(workflow.cores/9, 9)
    params:
        nom = lambda w: w.nom
    shell:
        """
        mkdir tempdir{params.nom}
        export TMPDIR=tempdir{params.nom}
        pairtools dedup --nproc-in {threads} \
          --output-stats {output.stats} \
          --mark-dups -o {output.dpps} {input.pps}
        rm -rf tempdir{params.nom}
        """

rule hic_filter:
    input:
        dpps = config["tool"] + "/output/temp/dedupe/{nom}_parsed_sorted_dedupe.pairsam.gz",
    output:
        filt = config["tool"] + "/output/temp/filt/{nom}_parsed_sorted_dedupe_filt.pairsam.gz"
    threads:
        1
    shell:
        """
        pairtools select  '(pair_type == "UU") or (pair_type == "UR") or (pair_type == "RU")' \
          -o {output.filt} {input.dpps}
        """

rule generate_final_pairs:
    """
    generate the final output from a pairsam to a pairs file
    """
    input:
        filt = config["tool"] + "/output/temp/filt/{nom}_parsed_sorted_dedupe_filt.pairsam.gz"
    output:
        final = config["tool"] + "/output/pairs/{nom}/{nom}.dedup.filt.pairs.gz"
    threads:
        1
    shell:
        """
        pairtools split --output-pairs {output.final} {input.filt}
        """

rule index_pairs:
    """
    indexing output. the *.pairs.gz suffix is important to parse the file correctly!
    """
    input:
        pairs = config["tool"] + "/output/pairs/{nom}/{nom}.dedup.filt.pairs.gz"
    output:
        index = config["tool"] + "/output/pairs/{nom}/{nom}.dedup.filt.pairs.gz.px2"
    threads:
        1
    shell:
        """
        pairix -f {input.pairs}
        """

rule make_bins_individual:
    """
    This makes the matrix and bins everything
    i.e. binsize: 5000 (high resolution), 500000 (lower resolution)
    """
    input:
        final = config["tool"] + "/output/pairs/{nom}/{nom}.dedup.filt.pairs.gz",
        index = config["tool"] + "/output/pairs/{nom}/{nom}.dedup.filt.pairs.gz.px2",
        cs = config["tool"] + "/output/{nom}/{nom}_chromsize.txt"
    output:
        cool = config["tool"] + "/output/{nom}/{nom}.{binsize}.cool"
    threads:
        1
    params:
        bs = lambda wildcards: wildcards.binsize,
        nom = lambda wildcards: wildcards.nom,
        outname = lambda wildcards: "{tool}/output/{nom}/{nom}.{binsize}.cool".format(
            tool=config["tool"], nom = wildcards.nom, binsize = wildcards.binsize )
    shell:
        """
        cooler cload pairix {input.cs}:{params.bs} {input.final} {params.outname}
        """

rule balance_matrix:
    """
    ## Matrix normalization/ balancing
    #cooler balance res.<binsize>.cool
    ## if any problems with creating output add "--force" option
    """
    input:
        cool = config["tool"] + "/output/{nom}/{nom}.{binsize}.cool"
    output:
        cool = config["tool"] + "/output/{nom}/{nom}_balanced.{binsize}.cool"
    shell:
        """
        cp {input.cool} {output.cool}
        cooler balance --force {output.cool}
        """

rule zoomify_matrix:
    """
    ## Aggregation (for HiGlass view) - This generates a *.mcool file from the balanced cool file
    """
    input:
        cool = config["tool"] + "/output/{nom}/{nom}_balanced.{binsize}.cool"
    output:
        mcool = config["tool"] + "/output/{nom}/{nom}_balanced.{binsize}.mcool"
    shell:
        """
        cooler zoomify -o {output.mcool} {input.cool}
        """

# This performs the AB-compartmentalization calculations on each cooler
rule PCA_of_matrix:
    """
    this makes a bigwig file of the PCAs of the balanced cooler files
    """
    input:
        cool = config["tool"] + "/output/{nom}/{nom}_balanced.{binsize}.cool"
    output:
        pca1 = config["tool"] + "/output/{nom}/ABcompartments/{nom}_balanced.{binsize}.pca1.bw",
        pca2 = config["tool"] + "/output/{nom}/ABcompartments/{nom}_balanced.{binsize}.pca2.bw"
    threads: 1
    shell:
        """
        hicPCA -m {input.cool} -o {output.pca1} {output.pca2} --format bigwig
        """

rule pearson_of_matrix:
    """
    this makes the pearson correlation matrix for the matrix.
    """
    input:
        cool = config["tool"] + "/output/{nom}/{nom}_balanced.{binsize}.cool"
    output:
        pearson = config["tool"] + "/output/{nom}/ABcompartments/{nom}_balanced.{binsize}.pearson.cool",
    threads: 1
    shell:
        """
        hicTransform --matrix {input.cool} -o {output.pearson} --method pearson
        """

rule plot_matrices:
    input:
        pearson = config["tool"] + "/output/{nom}/ABcompartments/{nom}_balanced.{binsize}.pearson.cool",
        pca1 = config["tool"] + "/output/{nom}/ABcompartments/{nom}_balanced.{binsize}.pca1.bw"
    output:
        pdf = config["tool"] + "/output/{nom}/ABcompartments/{nom}_balanced.{binsize}.ABplot.pdf"
    threads: 1
    shell:
        """
        hicPlotMatrix -m {input.pearson} --outFileName {output.pdf} --perChr --bigwig {input.pca1}
        """

## Now plot the gene interactions matrix
## get the list of chromosomes that we will keep for 3DGR
#
#rule gene_interactions_matrix:
#    input:
#        cool = config["tool"] + "/output/{nom}/{nom}_balanced.{binsize}.cool"
#    output:
#        giv = config["tool"] + "/output/{nom}/3DGR/{nom}_balanced.{binsize}.gi.tsv"
#    params:
#        giv = lambda w: config["tool"] + "/output/{nom}/3DGR/{nom}_balanced.{binsize}.gi".format(
#               nom = w.nom, binsize = w.binsize)
#    threads: 1
#    shell:
#        """
#        hicConvertFormat -m {input.cool} -o {params.giv} \
#           --inputFormat cool --outputFormat ginteractions
#        """
#
#rule convert_gi_to_if:
#    """
#    This converts the gi to an interaction frequency matrix used by LorDB
#    """
#    input:
#        giv = config["tool"] + "/output/{nom}/3DGR/{nom}_balanced.{binsize}.gi.tsv",
#        gi_to_if_script = os.path.join(filepath, "gi_to_if.py")
#    output:
#        giv = config["tool"] + "/output/{nom}/3DGR/{nom}_balanced.{binsize}.if.tsv"
#    threads: 1
#    shell:
#        """
#        cat {input.giv} | python {input.gi_to_if_script} > {output.giv}
#        """

# This part makes a pretext map
rule make_pretextmap:
    input:
        bam   = expand(config["tool"] + "/input/bams/{{nom}}_{lib}_to_ref.sorted.bam", lib=config["libs"]),
    output:
        pretext = config["tool"] + "/output/{nom}/{nom}.pretext"
    threads:
        1
    shell:
        """
        samtools cat -h {input.bam} | samtools view -h - | \
            PretextMap -o {output.pretext}
        """
